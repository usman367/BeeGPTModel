{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "816ff44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ffc1c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '17flowers'\n",
    "image_size = (128, 128) # Images will be resized to 128 by 128\n",
    "batch_size = 40\n",
    "num_classes = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0441396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA LOADING AND PREPROCESSING\n",
    "# Load the data and labels\n",
    "data = []\n",
    "labels = []\n",
    "class_names = sorted(os.listdir(os.path.join(data_dir))) # Read the class names\n",
    "# print(\"Class name: \", class_names)\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(data_dir, class_name) # Path to directory\n",
    "    for img_file in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_file) # Path to the image\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=image_size) # Load and resize the image\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img) # Convert the image to an array\n",
    "        \n",
    "        # Append the image and the class label to the respective lists\n",
    "        data.append(img)\n",
    "        labels.append(class_name)\n",
    "\n",
    "        \n",
    "data = np.array(data)\n",
    "# print(len(data))\n",
    "\n",
    "labels = np.array(labels)\n",
    "# print(\"Labels: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b92be4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_to_index:  {'Bluebell': 0, 'Buttercup': 1, 'Coltsfoot': 2, 'Cowslip': 3, 'Crocus': 4, 'Daffodil': 5, 'Daisy': 6, 'Dandelion': 7, 'Fritillary': 8, 'Iris': 9, 'Lily Valley': 10, 'Pansy': 11, 'Snowdrop': 12, 'Sunflower': 13, 'Tigerlily': 14, 'Tulip': 15, 'Windflower': 16}\n",
      "labels:  [ 0  0  0 ... 16 16 16]\n",
      "labels length:  1360\n",
      "x_train size:  952\n",
      "x_temp size:  408\n",
      "x_val size:  204\n",
      "y_val size:  204\n"
     ]
    }
   ],
   "source": [
    "### DATA CONVERSION AND SPLITTING\n",
    "### Convert class names to integer labels\n",
    "# Create a mapping from class name to integer labels\n",
    "label_to_index = {label: i for i, label in enumerate(class_names)}\n",
    "print(\"label_to_index: \", label_to_index)\n",
    "\n",
    "# Converts class names to integer labels\n",
    "labels = np.array([label_to_index[label] for label in labels])\n",
    "print(\"labels: \", labels)\n",
    "print(\"labels length: \", len(labels))\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "# 70% will be used for training\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "print(\"x_train size: \", len(x_train))\n",
    "print(\"x_temp size: \", len(x_temp))\n",
    "\n",
    "\n",
    "# SPlit the data from above validations and testing (15% each now)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n",
    "print(\"x_val size: \", len(x_val))\n",
    "print(\"y_val size: \", len(y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6163434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert integer labels to one-hot encoded labels\n",
    "# To respresent class labels as categorical vectors\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"y_train: \", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "522e2e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA NORMALIZATION\n",
    "# The RGB channel values are in the [0, 255] range.\n",
    "# This is not ideal for a neural network\n",
    "# Normalize the pixel values to [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "x_val = x_val / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "befbf18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 63, 63, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               3211392   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 17)                2193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3306833 (12.61 MB)\n",
      "Trainable params: 3306833 (12.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model with regularization\n",
    "inputs = Input(shape=(image_size[0], image_size[1], 3))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7adfcf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using Adam optimizer\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "badd3026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 16s 567ms/step - loss: 2.5782 - accuracy: 0.1544 - val_loss: 2.2679 - val_accuracy: 0.2745\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 13s 545ms/step - loss: 1.9439 - accuracy: 0.3624 - val_loss: 1.8815 - val_accuracy: 0.3676\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 13s 539ms/step - loss: 1.4706 - accuracy: 0.5095 - val_loss: 1.6182 - val_accuracy: 0.4020\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 13s 564ms/step - loss: 1.1185 - accuracy: 0.6261 - val_loss: 1.4425 - val_accuracy: 0.4755\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 13s 550ms/step - loss: 0.7841 - accuracy: 0.7353 - val_loss: 1.5561 - val_accuracy: 0.4951\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 14s 575ms/step - loss: 0.4739 - accuracy: 0.8445 - val_loss: 1.6847 - val_accuracy: 0.5245\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 13s 550ms/step - loss: 0.2539 - accuracy: 0.9254 - val_loss: 1.9964 - val_accuracy: 0.5588\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 14s 600ms/step - loss: 0.1213 - accuracy: 0.9685 - val_loss: 1.7804 - val_accuracy: 0.5392\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 14s 589ms/step - loss: 0.0604 - accuracy: 0.9874 - val_loss: 2.0334 - val_accuracy: 0.5441\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 13s 559ms/step - loss: 0.0429 - accuracy: 0.9842 - val_loss: 2.0453 - val_accuracy: 0.5882\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 14s 563ms/step - loss: 0.0184 - accuracy: 0.9979 - val_loss: 1.9711 - val_accuracy: 0.5980\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 13s 542ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.2833 - val_accuracy: 0.5784\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 13s 536ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1845 - val_accuracy: 0.5686\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 14s 571ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.2114 - val_accuracy: 0.5882\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 13s 552ms/step - loss: 6.0178e-04 - accuracy: 1.0000 - val_loss: 2.2512 - val_accuracy: 0.5882\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 13s 548ms/step - loss: 4.6386e-04 - accuracy: 1.0000 - val_loss: 2.2755 - val_accuracy: 0.5931\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 13s 551ms/step - loss: 3.9794e-04 - accuracy: 1.0000 - val_loss: 2.2926 - val_accuracy: 0.5882\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 13s 538ms/step - loss: 3.4623e-04 - accuracy: 1.0000 - val_loss: 2.3162 - val_accuracy: 0.5882\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 13s 540ms/step - loss: 3.1014e-04 - accuracy: 1.0000 - val_loss: 2.3321 - val_accuracy: 0.5931\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 13s 529ms/step - loss: 2.7704e-04 - accuracy: 1.0000 - val_loss: 2.3568 - val_accuracy: 0.5882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x170e8c09a50>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 20\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8cdff12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model.save(os.path.join('models','SeventeenClasses1.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ee935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
