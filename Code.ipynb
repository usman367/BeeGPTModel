{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "abf5c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02a45341",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '10flowers'\n",
    "image_size = (128, 128) # Images will be resized to 128 by 128\n",
    "batch_size = 40\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "332d96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA LOADING AND PREPROCESSING\n",
    "# Load the data and labels\n",
    "data = []\n",
    "labels = []\n",
    "class_names = sorted(os.listdir(os.path.join(data_dir))) # Read the class names\n",
    "# print(\"Class name: \", class_names)\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(data_dir, class_name) # Path to directory\n",
    "    for img_file in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_file) # Path to the image\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=image_size) # Load and resize the image\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img) # Convert the image to an array\n",
    "        \n",
    "        # Append the image and the class label to the respective lists\n",
    "        data.append(img)\n",
    "        labels.append(class_name)\n",
    "\n",
    "        \n",
    "data = np.array(data)\n",
    "# print(len(data))\n",
    "\n",
    "labels = np.array(labels)\n",
    "# print(\"Labels: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "50ceade9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_to_index:  {'Bluebell': 0, 'Crocus': 1, 'Daffodil': 2, 'Daisy': 3, 'Fritillary': 4, 'Iris': 5, 'Lily Valley': 6, 'Snowdrop': 7, 'Sunflower': 8, 'Tulip': 9}\n",
      "labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "labels length:  800\n",
      "x_train size:  560\n",
      "x_temp size:  240\n",
      "x_val size:  120\n",
      "y_val size:  120\n"
     ]
    }
   ],
   "source": [
    "### DATA CONVERSION AND SPLITTING\n",
    "### Convert class names to integer labels\n",
    "# Create a mapping from class name to integer labels\n",
    "label_to_index = {label: i for i, label in enumerate(class_names)}\n",
    "print(\"label_to_index: \", label_to_index)\n",
    "\n",
    "# Converts class names to integer labels\n",
    "labels = np.array([label_to_index[label] for label in labels])\n",
    "print(\"labels: \", labels)\n",
    "print(\"labels length: \", len(labels))\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "# 70% will be used for training\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "print(\"x_train size: \", len(x_train))\n",
    "print(\"x_temp size: \", len(x_temp))\n",
    "\n",
    "\n",
    "# SPlit the data from above validations and testing (15% each now)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n",
    "print(\"x_val size: \", len(x_val))\n",
    "print(\"y_val size: \", len(y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4060016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert integer labels to one-hot encoded labels\n",
    "# To respresent class labels as categorical vectors\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"y_train: \", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "04a3f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA NORMALIZATION\n",
    "# The RGB channel values are in the [0, 255] range.\n",
    "# This is not ideal for a neural network\n",
    "# Normalize the pixel values to [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "x_val = x_val / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4cc38cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 63, 63, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 30, 30, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 14, 14, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               3211392   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3305930 (12.61 MB)\n",
      "Trainable params: 3305930 (12.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model with regularization\n",
    "inputs = Input(shape=(image_size[0], image_size[1], 3))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "135446f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using Adam optimizer\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6224a26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 10s 587ms/step - loss: 2.2473 - accuracy: 0.1821 - val_loss: 1.8626 - val_accuracy: 0.3000\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 8s 558ms/step - loss: 1.6190 - accuracy: 0.4089 - val_loss: 1.6954 - val_accuracy: 0.4000\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 9s 632ms/step - loss: 1.2185 - accuracy: 0.5589 - val_loss: 1.3397 - val_accuracy: 0.5417\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 9s 641ms/step - loss: 0.8935 - accuracy: 0.6839 - val_loss: 1.2675 - val_accuracy: 0.6083\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 8s 555ms/step - loss: 0.6146 - accuracy: 0.7911 - val_loss: 1.0160 - val_accuracy: 0.7083\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 8s 541ms/step - loss: 0.5900 - accuracy: 0.8107 - val_loss: 1.2522 - val_accuracy: 0.6083\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 7s 535ms/step - loss: 0.3320 - accuracy: 0.8929 - val_loss: 1.0462 - val_accuracy: 0.6833\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 8s 548ms/step - loss: 0.1983 - accuracy: 0.9446 - val_loss: 1.1733 - val_accuracy: 0.6833\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 7s 523ms/step - loss: 0.1113 - accuracy: 0.9714 - val_loss: 1.5390 - val_accuracy: 0.6583\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 7s 519ms/step - loss: 0.0537 - accuracy: 0.9929 - val_loss: 1.3046 - val_accuracy: 0.7083\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 8s 545ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.3136 - val_accuracy: 0.7333\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 8s 538ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.3364 - val_accuracy: 0.7083\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 8s 540ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4024 - val_accuracy: 0.7167\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 8s 538ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4325 - val_accuracy: 0.7250\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 7s 536ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4559 - val_accuracy: 0.7083\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 8s 549ms/step - loss: 9.0486e-04 - accuracy: 1.0000 - val_loss: 1.4742 - val_accuracy: 0.7167\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 7s 527ms/step - loss: 7.6063e-04 - accuracy: 1.0000 - val_loss: 1.4882 - val_accuracy: 0.7250\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 8s 541ms/step - loss: 6.6407e-04 - accuracy: 1.0000 - val_loss: 1.5058 - val_accuracy: 0.7250\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 7s 532ms/step - loss: 5.8526e-04 - accuracy: 1.0000 - val_loss: 1.5224 - val_accuracy: 0.7167\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 8s 585ms/step - loss: 5.1520e-04 - accuracy: 1.0000 - val_loss: 1.5416 - val_accuracy: 0.7250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x170e8cc1fd0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 20\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs)w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1ac8fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model.save(os.path.join('models','TenClasses1.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c37f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
